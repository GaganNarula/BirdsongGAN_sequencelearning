{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'/home/songbird/Dropbox/Work/MDGAN_paper/code/Gagan/Train')\n",
    "from utils import *\n",
    "from hmmlearn import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from time import time\n",
    "from sklearn.externals import joblib\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath2models = '/media/songbird/datapartition/HMM/trained_models/merge_6000'\n",
    "tutor_path = '/media/songbird/datapartition/HMM/trained_models/tutor/models/100h_gauss_diag.pkl'\n",
    "\n",
    "pupil_paths = [glob(os.path.join(basepath2models, 'm0_b7r16','models', 'm0_150h_gauss_diag.pkl'))[0],\n",
    "                glob(os.path.join(basepath2models, 'm1_b7r16','models', 'm1_150h_gauss_diag.pkl'))[0],\n",
    "               glob(os.path.join(basepath2models, 'm2_b7r16','models', 'm2_130h_gauss_diag.pkl'))[0],\n",
    "               glob(os.path.join(basepath2models, 'm3_b7r16','models', 'm3_150h_gauss_diag.pkl'))[0],\n",
    "               glob(os.path.join(basepath2models, 'm4_b7r16','models', 'm4_150h_gauss_diag.pkl'))[0],\n",
    "               glob(os.path.join(basepath2models, 'm5_b7r16','models', 'm5_150h_gauss_diag.pkl'))[0],\n",
    "               glob(os.path.join(basepath2models, 'm6_b7r16','models', 'm6_150h_gauss_diag.pkl'))[0]]\n",
    "\n",
    "zseq_folders = ['day9_b7r16', 'day12_b7r16', 'day16_b7r16', 'day19_b7r16', 'day22_b7r16', 'day25_b7r16', 'day28_b7r16']\n",
    "\n",
    "bird_path = '/home/songbird/data/b7r16_val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def viterbi_sample(X,model,covtype='diag'):\n",
    "    #X is a sequence\n",
    "    #calculate most likely path given X under the model\n",
    "    #return a sample from that path\n",
    "    _, Z = model.decode(X)#contains information for all states\n",
    "    L=len(Z)-1 #all states minus the start-state which is not defined in our case\n",
    "    sequence=[]\n",
    "    #take a sample from each state-emission\n",
    "    for i in range(L):\n",
    "        mean_i = model.means_[Z[i+1]]\n",
    "        if covtype=='diag':\n",
    "            sigma_i = model.covars_[Z[i+1]]\n",
    "        elif covtype=='tied':\n",
    "            sigma_i = model.covars_\n",
    "        elif covtype=='spherical':\n",
    "            sigma_i = model.covars_[Z[i+1]]\n",
    "            sigma_i = np.diag(np.repeat(sigma_i, repeats=X.shape[1]))\n",
    "        else:\n",
    "            # case \"full\"\n",
    "            sigma_i = model.covars_[Z[i+1]]\n",
    "        \n",
    "        #sequence.append(np.random.multivariate_normal(mean_i,sigma_i,size=1))\n",
    "        sequence.append(mean_i)\n",
    "    # print (np.asarray(sequence).shape)\n",
    "    return sequence\n",
    "\n",
    "\n",
    "def rescale_spectrogram(s):\n",
    "    if np.min(s) < 0:\n",
    "        s = s - np.min(s) \n",
    "    s = s/np.max(s)\n",
    "    return 10*np.log10(s + 0.01)\n",
    "\n",
    "\n",
    "def decode(zhat, netG, method=1, give_audio = False, imageH=129, imageW=16, cuda = False):\n",
    "    '''\n",
    "    Input zhat should have correct number of steps, i.e. if the spectrogram to be decoded has \n",
    "    X time frames, then you should input the vector z[: round(X / imageW), :]. This is due to \n",
    "    batch_size effects in pytorch!\n",
    "    '''\n",
    "    if type(zhat)==np.ndarray:\n",
    "        zhat = torch.from_numpy(zhat).float()\n",
    "        zhat = zhat.resize_(zhat.shape[0], zhat.shape[1], 1, 1)\n",
    "    if cuda:\n",
    "        zhat = zhat.cuda()\n",
    "    out_shape = [imageH, imageW]\n",
    "    reconstructed_samples = []\n",
    "    reconstruction = netG(zhat)\n",
    "     \n",
    "    for k in range(reconstruction.data.cpu().numpy().shape[0]):\n",
    "        if method==1:\n",
    "            reconstructed_samples.append(reconstruction.data[k,:,:,:].cpu().numpy().reshape(out_shape))\n",
    "        elif method==2:\n",
    "            reconstructed_samples.append( \\\n",
    "                                        inverse_transform(reconstruction.data[k,:,:,:].cpu().numpy().reshape(out_shape), N=500))\n",
    "        elif method==3:\n",
    "            reconstructed_samples.append(get_spectrogram(rescale_spectrogram(reconstruction.data[k,:,:,:].cpu().numpy().reshape(out_shape))))\n",
    "        \n",
    "    reconstructed_samples = np.concatenate(reconstructed_samples, axis=1)\n",
    "    if give_audio and method==2:\n",
    "        reconstructed_audio = lc.istft(reconstructed_samples)\n",
    "    else:\n",
    "        reconstructed_audio = []\n",
    "    return rescale_spectrogram(reconstructed_samples), reconstructed_audio\n",
    "\n",
    "\n",
    "def decode_by_batch(zhat, netG,  batch_size = 64, imageH=129, imageW=16, cuda = False):\n",
    "    if type(zhat)==np.ndarray:\n",
    "        zhat = torch.from_numpy(zhat).float()\n",
    "        zhat = zhat.resize_(zhat.shape[0], zhat.shape[1], 1, 1)\n",
    "    if cuda:\n",
    "        zhat = zhat.cuda()\n",
    "    out_shape = [imageH, imageW]\n",
    "    reconstructed_samples = []\n",
    "    # do inference in batches\n",
    "    nbatches = round(zhat.size(0)/batch_size)\n",
    "    i = 0\n",
    "    for n in range(nbatches):\n",
    "        reconstruction = netG(zhat[i:i+batch_size])\n",
    "        i += batch_size\n",
    "        for k in range(reconstruction.data.cpu().numpy().shape[0]):\n",
    "            reconstructed_samples.append(reconstruction.data[k,:,:,:].cpu().numpy().reshape(out_shape))\n",
    "    reconstructed_samples = np.concatenate(reconstructed_samples, axis=1)\n",
    "    return rescale_spectrogram(reconstructed_samples)\n",
    "    \n",
    "def load_z_and_remove_redundant(path2fls):\n",
    "    fls = os.listdir(path2fls)\n",
    "    zseqs = []\n",
    "    for f in fls:\n",
    "        z = np.load(os.path.join(path2fls, f))\n",
    "        zprev = z[0]\n",
    "        seq = []\n",
    "        seq.append(zprev)\n",
    "        for i in range(1,len(z)):\n",
    "            if np.sum(z[i]-zprev)!=0.0:\n",
    "                seq.append(z[i])\n",
    "                zprev = z[i]\n",
    "            else:\n",
    "                break\n",
    "        seq = np.array(seq)\n",
    "        zseqs.append(seq)\n",
    "    return zseqs\n",
    "\n",
    "\n",
    "def create_merged_sets(zseqs, required_len = 100):\n",
    "    step_cntr = 0\n",
    "    allseq = []\n",
    "    seq = []\n",
    "    for i in range(len(zseqs)):\n",
    "        if step_cntr < required_len:\n",
    "            seq.append(zseqs[i])\n",
    "            step_cntr += zseqs[i].shape[0]\n",
    "        else:\n",
    "            allseq.append(np.concatenate(seq, axis=0))\n",
    "            seq = []\n",
    "            step_cntr = 0\n",
    "    return allseq\n",
    "\n",
    "\n",
    "def get_random_zsequence_sample_from_bird(birdpath, folder_names, Nsamps = 50):\n",
    "    folder_zseq = []\n",
    "    for f in folder_names:\n",
    "        path2files = os.path.join(birdpath, f, 'z_sequences/')\n",
    "        allfiles = os.listdir(path2files)\n",
    "        idx = np.random.choice(len(allfiles),size=Nsamps,replace=False)\n",
    "        zseq = [None for i in range(len(idx))]\n",
    "        for k in range(len(idx)):\n",
    "            # load z-sequence\n",
    "            z = np.load(os.path.join(path2files, allfiles[k]))\n",
    "            zprev = z[0]\n",
    "            seq = []\n",
    "            seq.append(zprev)\n",
    "            for i in range(1,len(z)):\n",
    "                if np.sum(z[i]-zprev)!=0.0:\n",
    "                    seq.append(z[i])\n",
    "                    zprev = z[i]\n",
    "                else:\n",
    "                    break\n",
    "            seq = np.array(seq)\n",
    "            zseq[k] = seq\n",
    "        folder_zseq.append(zseq)\n",
    "    return folder_zseq\n",
    "\n",
    "\n",
    "def tempered_sampling(model, beta=3., timesteps=64, sample_obs=True, start_state_max=False):\n",
    "    # start probability sample\n",
    "    if start_state_max:\n",
    "        row = np.argmax(model.startprob_)\n",
    "    else:\n",
    "        # choose a start state\n",
    "        p = np.exp(beta * np.log(model.startprob_))\n",
    "        p /= np.sum(p)\n",
    "        s0 = np.random.multinomial(1,p)\n",
    "        row = np.where(s0==1.)[0][0]\n",
    "    s0 = row\n",
    "    states = np.zeros((timesteps),dtype='int64')\n",
    "    obs = np.zeros((timesteps, model.means_.shape[-1]))\n",
    "    for i in range(timesteps):\n",
    "        # extract the correct row from the transition matrix\n",
    "        a = model.transmat_[row,:]\n",
    "        # make the gibbs probability vector\n",
    "        p = np.exp(beta * np.log(a))\n",
    "        p /= np.sum(p)\n",
    "        # sample from it \n",
    "        s = np.random.multinomial(1,p)\n",
    "        row = np.where(s==1.)[0][0]\n",
    "        states[i] = row\n",
    "        # sample from the corresponding distribution in the model\n",
    "        mean_i = model.means_[row]\n",
    "        sigma_i = model.covars_[row]\n",
    "        if sample_obs:\n",
    "            # sample an observation \n",
    "            obs[i] = np.random.multivariate_normal(mean_i,sigma_i,size=1)\n",
    "        else:\n",
    "            obs[i] = mean_i\n",
    "    return obs, states, s0\n",
    "\n",
    "\n",
    "def sample_and_compute_single_score(model1, model2, beta,  timesteps, sample_obs, start_state_max):\n",
    "    z,_,_ = tempered_sampling(model1, beta, timesteps, sample_obs, start_state_max)\n",
    "    m1score = model1.score(z)\n",
    "    m2score = model2.score(z)\n",
    "    dpq = (1/timesteps)*(m1score - m2score)\n",
    "    \n",
    "    # now do dqp\n",
    "    z,_,_ = tempered_sampling(model2, beta, timesteps, sample_obs, start_state_max)\n",
    "    m2score = model2.score(z)\n",
    "    m1score = model1.score(z)\n",
    "    dqp = (1/timesteps)*(m2score - m1score)\n",
    "    \n",
    "    # symmetric score Jensen Shannon\n",
    "    js = 0.5*dpq + 0.5*dqp\n",
    "    return dpq, dqp, js\n",
    "\n",
    "\n",
    "def compute_single_score_from_observation(zseq, model1, model2):\n",
    "    '''\n",
    "    Zseq is a sequence of latent variable vectors [timesteps x ndim]\n",
    "    '''\n",
    "    timesteps = zseq.shape[0]\n",
    "    m1score = model1.score(zseq)\n",
    "    m2score = model2.score(zseq)\n",
    "    dpq = (1/timesteps)*(m1score - m2score)\n",
    "    \n",
    "    # now do dqp\n",
    "    dqp = (1/timesteps)*(m2score - m1score)\n",
    "    \n",
    "    # symmetric score Jensen Shannon\n",
    "    js = 0.5*dpq + 0.5*dqp\n",
    "    return dpq, dqp, js\n",
    "\n",
    "\n",
    "def juang_rabiner_HMM_dist(model1, model2, zseq_data = [], min_len = 40, beta = 1., Nsamp = 100000, \\\n",
    "                           timesteps = np.arange(start=40, stop=60, step=1), do_parallel=True):\n",
    "    '''\n",
    "    DKL(P||Q), DKL(Q||P), JS(P,Q) for two cases:\n",
    "        1. When actual data is available (zseq_data)\n",
    "        2. When samples are generated from model1 (P), assumed to be tutor\n",
    "    '''\n",
    "    Scores_per_len = []\n",
    "    pdb.set_trace()\n",
    "    if zseq_data:\n",
    "        # for each given sequence, get scores (DKL[P||Q],DKL[Q||P],JS(P,Q))\n",
    "        score = []\n",
    "        for i,z in enumerate(zseq_data):\n",
    "            score.append(compute_single_score_from_observation(z, model1, model2))\n",
    "            if i%10==9:\n",
    "                print('# %d/%d data sequences processed '%(i/len(zseq_data)))\n",
    "        Scores_per_len.append([(np.mean([s[0] for s in score]),np.var([s[0] for s in score])), \\\n",
    "                               (np.mean([s[1] for s in score]),np.var([s[1] for s in score])), \\\n",
    "                               (np.mean([s[2] for s in score]),np.var([s[2] for s in score]))])\n",
    "    else:\n",
    "        for k in timesteps:\n",
    "            if not do_parallel:\n",
    "                score = []\n",
    "                for n in range(Nsamp):\n",
    "                    score.append(sample_and_compute_single_score(model1, model2, beta, k, sample_obs=False, start_state_max=True))\n",
    "            else:\n",
    "                score = Parallel(n_jobs=-3)(delayed(sample_and_compute_single_score)(model1, model2, \\\n",
    "                                                                                     beta, k, \\\n",
    "                                                                                     sample_obs=False, \\\n",
    "                                                                                     start_state_max=True) for n in range(Nsamp))\n",
    "        \n",
    "            # take the average score per length\n",
    "            Scores_per_len.append([(np.mean([s[0] for s in score]),np.var([s[0] for s in score])), \\\n",
    "                                   (np.mean([s[1] for s in score]),np.var([s[1] for s in score])), \\\n",
    "                                   (np.mean([s[2] for s in score]),np.var([s[2] for s in score]))])\n",
    "        if k%10==9:\n",
    "            print('# %d/%d time steps simulated'%(k,len(timesteps)))\n",
    "            \n",
    "    return Scores_per_len\n",
    "\n",
    "\n",
    "def compute_LL_HMM_dist(pupil_paths, tutor_path, birdpath = [], zseq_folders = [], pupdatasamps=50, beta = 3., Nsamp=100000, \\\n",
    "                        seq_lengths = np.arange(start=40, stop=60, step=1), do_parallel=False):\n",
    "    tutorhmm = joblib.load(tutor_path)\n",
    "    if zseq_folders:\n",
    "        zseq_data = get_random_zsequence_sample_from_bird(birdpath, zseq_folders, Nsamps = pupdatasamps)\n",
    "    scores = []\n",
    "    pdb.set_trace()\n",
    "    for i,p in enumerate(pupil_paths):\n",
    "        start = time()\n",
    "        print('\\n ....... pupil merge number %d/%d .......'%(i,len(pupil_paths)))\n",
    "        pupilhmm = joblib.load(p)\n",
    "        per_day_score_list = juang_rabiner_HMM_dist(tutorhmm, pupilhmm, zseq_data[i], beta, Nsamp, seq_lengths, do_parallel)\n",
    "        scores.append(per_day_score_list) \n",
    "        end = time()\n",
    "        print('\\n ....... time taken for this merge = %5d secs........ '%(end-start))\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-5-08ac6d953720>(253)compute_LL_HMM_dist()\n",
      "-> for i,p in enumerate(pupil_paths):\n",
      "> <ipython-input-5-08ac6d953720>(254)compute_LL_HMM_dist()\n",
      "-> start = time()\n",
      "> <ipython-input-5-08ac6d953720>(255)compute_LL_HMM_dist()\n",
      "-> print('\\n ....... pupil merge number %d/%d .......'%(i,len(pupil_paths)))\n",
      "\n",
      " ....... pupil merge number 0/7 .......\n",
      "> <ipython-input-5-08ac6d953720>(256)compute_LL_HMM_dist()\n",
      "-> pupilhmm = joblib.load(p)\n",
      "> <ipython-input-5-08ac6d953720>(257)compute_LL_HMM_dist()\n",
      "-> per_day_score_list = juang_rabiner_HMM_dist(tutorhmm, pupilhmm, zseq_data[i], beta, Nsamp, seq_lengths, do_parallel)\n",
      "--Call--\n",
      "> <ipython-input-5-08ac6d953720>(214)juang_rabiner_HMM_dist()\n",
      "-> def juang_rabiner_HMM_dist(model1, model2, zseq_data = [], min_len = 40, beta = 1., Nsamp = 100000,                            timesteps = np.arange(start=40, stop=60, step=1), do_parallel=True):\n",
      "> <ipython-input-5-08ac6d953720>(220)juang_rabiner_HMM_dist()\n",
      "-> Scores_per_len = []\n",
      "> <ipython-input-5-08ac6d953720>(221)juang_rabiner_HMM_dist()\n",
      "-> pdb.set_trace()\n",
      "> <ipython-input-5-08ac6d953720>(222)juang_rabiner_HMM_dist()\n",
      "-> if zseq_data:\n",
      "> <ipython-input-5-08ac6d953720>(224)juang_rabiner_HMM_dist()\n",
      "-> score = []\n",
      "> <ipython-input-5-08ac6d953720>(225)juang_rabiner_HMM_dist()\n",
      "-> for i,z in enumerate(zseq_data):\n",
      "50\n",
      "> <ipython-input-5-08ac6d953720>(226)juang_rabiner_HMM_dist()\n",
      "-> score.append(compute_single_score_from_observation(z, model1, model2))\n",
      "> <ipython-input-5-08ac6d953720>(227)juang_rabiner_HMM_dist()\n",
      "-> if i%10==9:\n",
      "> <ipython-input-5-08ac6d953720>(225)juang_rabiner_HMM_dist()\n",
      "-> for i,z in enumerate(zseq_data):\n",
      "> <ipython-input-5-08ac6d953720>(226)juang_rabiner_HMM_dist()\n",
      "-> score.append(compute_single_score_from_observation(z, model1, model2))\n",
      "[(-34.87027457510074, 34.87027457510074, 0.0)]\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8115babba88f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_LL_HMM_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpupil_paths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtutor_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbird_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mzseq_folders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-08ac6d953720>\u001b[0m in \u001b[0;36mcompute_LL_HMM_dist\u001b[0;34m(pupil_paths, tutor_path, birdpath, zseq_folders, pupdatasamps, beta, Nsamp, seq_lengths, do_parallel)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n ....... pupil merge number %d/%d .......'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpupil_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mpupilhmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mper_day_score_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjuang_rabiner_HMM_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtutorhmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpupilhmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzseq_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNsamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_parallel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mper_day_score_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-08ac6d953720>\u001b[0m in \u001b[0;36mjuang_rabiner_HMM_dist\u001b[0;34m(model1, model2, zseq_data, min_len, beta, Nsamp, timesteps, do_parallel)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzseq_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_single_score_from_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'# %d/%d data sequences processed '\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzseq_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-08ac6d953720>\u001b[0m in \u001b[0;36mjuang_rabiner_HMM_dist\u001b[0;34m(model1, model2, zseq_data, min_len, beta, Nsamp, timesteps, do_parallel)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzseq_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_single_score_from_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'# %d/%d data sequences processed '\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzseq_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/oldsklearn/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/oldsklearn/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores = compute_LL_HMM_dist(pupil_paths,tutor_path,bird_path,zseq_folders,beta=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
